{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellpose for Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "By the end of this module, learners will be able to:\n",
    "- Understand what Cellpose is and why it’s useful in bioimage analysis.\n",
    "- Load images and select the correct Cellpose model and parameters.\n",
    "- Run segmentation using Cellpose and visualize the results.\n",
    "- Avoid common pitfalls when using Cellpose.\n",
    "- Apply their knowledge in a small project to segment real-world biological images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cellpose\n",
    "**What is Cellpose?**\n",
    "**Cellpose** is a generalist, deep learning-based segmentation algorithm trained on various types of microscopy images. It works out of the box for many biological datasets without retraining. It supports:\n",
    "- 2D and 3D segmentation\n",
    "- Pretrained models for nuclei, cells (cytoplasm), bacteria, and more\n",
    "- Both GUI and Python API usage\n",
    "\n",
    "**Why it matters?**\n",
    "- Traditional segmentation (e.g., thresholding or watershed) often fails on complex or noisy images.\n",
    "- Cellpose leverages deep learning to segment cells even in challenging conditions, making it ideal for non-programmers and programmers alike.\n",
    "\n",
    "### Hands-On Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: cellpose[all]\r\n"
     ]
    }
   ],
   "source": [
    "# Install Cellpose if not already done\n",
    "!pip install cellpose[all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.5.dev23+g15eb3c6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from cellpose import models, io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- What kind of images might benefit from Cellpose segmentation?\n",
    "- Compare a threshold-based method to Cellpose (briefly, using napari if desired)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## How to Use Cellpose – Inputs, Model Types, Parameters\n",
    "**Inputs:** Single images or folders of .tif, .png, or .jpg images\n",
    "\n",
    "**Models:**\n",
    "- `cyto`: Cytoplasm\n",
    "- `nuclei`: Nuclei\n",
    "- `bact`: Bacteria (newer versions)\n",
    "\n",
    "**Key Parameters:**\n",
    "- `diameter`: Approximate object size (set to 0 for automatic estimation)\n",
    "- `channels`: [cytoplasm_channel, nucleus_channel]\n",
    "- `flow_threshold` and `cellprob_threshold`: Influence mask quality and confidence\n",
    "\n",
    "### Hands-On Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ranit/Research/github/Global-BioImaging-Image-Data-2025-Course---India/course_material/06182025_day3/cell_image.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/5t/3zkcp0dd27s3txcmjn8jl96m0000gq/T/ipykernel_19435/3623595192.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m image = imread(\u001b[33m'cell_image.tif'\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[32m      5\u001b[39m model = models.Cellpose(gpu=\u001b[38;5;28;01mFalse\u001b[39;00m, model_type=\u001b[33m'cyto'\u001b[39m)\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/skimage/_shared/utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m                 \u001b[38;5;28;01melif\u001b[39;00m self.new_name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    325\u001b[39m                     \u001b[38;5;66;03m# Assign old value to new one\u001b[39;00m\n\u001b[32m    326\u001b[39m                     kwargs[self.new_name] = deprecated_value\n\u001b[32m    327\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/skimage/io/_io.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(fname, as_gray, plugin, **plugin_args)\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fname.lower().endswith((\u001b[33m'.tiff'\u001b[39m, \u001b[33m'.tif'\u001b[39m)):\n\u001b[32m     79\u001b[39m             plugin = \u001b[33m'tifffile'\u001b[39m\n\u001b[32m     80\u001b[39m \n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname, _hide_plugin_deprecation_warnings():\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         img = call_plugin(\u001b[33m'imread'\u001b[39m, fname, plugin=plugin, **plugin_args)\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m hasattr(img, \u001b[33m'ndim'\u001b[39m):\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/skimage/_shared/utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m         @functools.wraps(func)\n\u001b[32m    535\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m wrapped(*args, **kwargs):\n\u001b[32m    536\u001b[39m             stacklevel = \u001b[32m1\u001b[39m + self.get_stack_length(func) - stack_rank\n\u001b[32m    537\u001b[39m             warnings.warn(message, category=FutureWarning, stacklevel=stacklevel)\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/skimage/io/manage_plugins.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(kind, *args, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m             func = [f \u001b[38;5;28;01mfor\u001b[39;00m (p, f) \u001b[38;5;28;01min\u001b[39;00m plugin_funcs \u001b[38;5;28;01mif\u001b[39;00m p == plugin][\u001b[32m0\u001b[39m]\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m IndexError:\n\u001b[32m    252\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m RuntimeError(f'Could not find the plugin \"{plugin}\" for {kind}.')\n\u001b[32m    253\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/skimage/io/_plugins/tifffile_plugin.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(fname, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m     \"\"\"\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'img_num'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m kwargs:\n\u001b[32m     72\u001b[39m         kwargs[\u001b[33m'key'\u001b[39m] = kwargs.pop(\u001b[33m'img_num'\u001b[39m)\n\u001b[32m     73\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tifffile_imread(fname, **kwargs)\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(files, selection, aszarr, key, series, level, squeeze, maxworkers, buffersize, mode, name, offset, size, pattern, axesorder, categories, imread, imreadargs, sort, container, chunkshape, chunkdtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[39m\n\u001b[32m   1195\u001b[39m         ):\n\u001b[32m   1196\u001b[39m             files = files[\u001b[32m0\u001b[39m]\n\u001b[32m   1197\u001b[39m \n\u001b[32m   1198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(files, str) \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(files, Sequence):\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m             with TiffFile(\n\u001b[32m   1200\u001b[39m                 files,\n\u001b[32m   1201\u001b[39m                 mode=mode,\n\u001b[32m   1202\u001b[39m                 name=name,\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[39m\n\u001b[32m   4230\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'invalid OME-XML'\u001b[39m)\n\u001b[32m   4231\u001b[39m             self._omexml = omexml\n\u001b[32m   4232\u001b[39m             self.is_ome = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   4233\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m4234\u001b[39m         fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\u001b[32m   4235\u001b[39m         self._fh = fh\n\u001b[32m   4236\u001b[39m         self._multifile = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _multifile \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(_multifile)\n\u001b[32m   4237\u001b[39m         self._files = {fh.name: self}\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, file, mode, name, offset, size)\u001b[39m\n\u001b[32m  13273\u001b[39m         self._offset = -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m offset\n\u001b[32m  13274\u001b[39m         self._size = -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m size\n\u001b[32m  13275\u001b[39m         self._close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m  13276\u001b[39m         self._lock = NullContext()\n\u001b[32m> \u001b[39m\u001b[32m13277\u001b[39m         self.open()\n\u001b[32m  13278\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m self._fh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m~/anaconda3/envs/gbi-python-env/lib/python3.13/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  13292\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._mode \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m {\u001b[33m'rb'\u001b[39m, \u001b[33m'r+b'\u001b[39m, \u001b[33m'wb'\u001b[39m, \u001b[33m'xb'\u001b[39m}:\n\u001b[32m  13293\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f'invalid mode {self._mode}')\n\u001b[32m  13294\u001b[39m             self._file = os.path.realpath(self._file)\n\u001b[32m  13295\u001b[39m             self._dir, self._name = os.path.split(self._file)\n\u001b[32m> \u001b[39m\u001b[32m13296\u001b[39m             self._fh = open(self._file, self._mode, encoding=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m  13297\u001b[39m             self._close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m  13298\u001b[39m             self._offset = max(\u001b[32m0\u001b[39m, self._offset)\n\u001b[32m  13299\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m isinstance(self._file, FileHandle):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/ranit/Research/github/Global-BioImaging-Image-Data-2025-Course---India/course_material/06182025_day3/cell_image.tif'"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "image = imread('cell_image.tif')\n",
    "\n",
    "# Create model\n",
    "model = models.Cellpose(gpu=False, model_type='cyto')\n",
    "\n",
    "# Run segmentation\n",
    "masks, flows, styles, diams = model.eval(image, diameter=0, channels=[0, 0])\n",
    "\n",
    "# Visualize\n",
    "io.masks_flows_to_seg(image, masks, flows, diams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Try segmenting a nucleus image with `model_type='nuclei'`.\n",
    "- Try changing diameter and see the effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Segmentation & Visualize Results\n",
    "\n",
    "**The output of Cellpose includes:**\n",
    "- `masks`: Segmented objects\n",
    "- `flows`: Internal representation of object movement during mask generation\n",
    "- `diams`: Estimated object sizes\n",
    "\n",
    "**Visualization tools:**\n",
    "- Napari (interactive)\n",
    "- matplotlib (static plots)\n",
    "- Cellpose GUI\n",
    "\n",
    "### Hands-On Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(masks, cmap='jet')\n",
    "plt.title(\"Cellpose Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Try visualizing masks overlaid on the original image.\n",
    "- Color-code different cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tips and Common Pitfalls\n",
    "**Tips:**\n",
    "- Use automatic diameter estimation unless you know the object size.\n",
    "- Try different model types if default fails.\n",
    "- Crop the image to test faster.\n",
    "\n",
    "**Common Pitfalls:**\n",
    "- Wrong channel settings (e.g., using RGB images without setting channels right)\n",
    "- Very large images can crash; downsample if needed\n",
    "- Don’t over-trust results – visually inspect masks\n",
    "\n",
    "### Hands-On Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example: downsampling image\n",
    "from skimage.transform import rescale\n",
    "\n",
    "small_image = rescale(image, 0.5, anti_aliasing=True)\n",
    "masks_small, *_ = model.eval(small_image, diameter=0, channels=[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Try segmenting with incorrect channels and observe the result.\n",
    "- Run Cellpose on a small crop and compare with full image segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mini Project: Segment Your Own Microscopy Image\n",
    "**Goal:** Apply Cellpose to segment nuclei or cells in a microscopy image of your choice and evaluate the output quality.\n",
    "\n",
    "**Instructions:**\n",
    "- Choose a .tif or .png image from your dataset.\n",
    "- Decide on the model type (cyto or nuclei).\n",
    "- Run segmentation using appropriate parameters.\n",
    "- Visualize the original + mask.\n",
    "\n",
    "**Reflect on:**\n",
    "1. Was the segmentation accurate?\n",
    "2. Which parameter changes improved results?\n",
    "3. Would you trust these results for quantification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module Summary\n",
    "| Topic                     | Key Takeaways                                                     |\n",
    "| ------------------------- | ----------------------------------------------------------------- |\n",
    "| What is Cellpose?         | A generalist deep learning model for cell/nucleus segmentation    |\n",
    "| Input, Models, Parameters | Choose correct model, tune `diameter` and `channels`              |\n",
    "| Running & Visualizing     | Use Python or GUI, visualize with `matplotlib` or Napari          |\n",
    "| Tips & Pitfalls           | Check channels, start with small crops, validate visually         |\n",
    "| Mini Project              | Apply on real image, tune parameters, assess segmentation quality |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}