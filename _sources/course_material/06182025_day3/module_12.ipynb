{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Basics for Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "By the end of this module, learners will be able to:\n",
    "- Understand what a Convolutional Neural Network (CNN) is and why it's useful in image analysis.\n",
    "- Recognize the importance of deep learning in image segmentation tasks.\n",
    "- Identify key Python libraries used for deep learning in imaging.\n",
    "- Prepare input and interpret output for image-based deep learning models.\n",
    "- Implement and evaluate a simple CNN-based segmentation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convolutional Neural Network\n",
    "A Convolutional Neural Network (CNN) is a type of artificial neural network designed specifically to process and learn from images.\n",
    "\n",
    "**Key building blocks:**\n",
    "- **Convolution layers:** detect features like edges, textures, shapes.\n",
    "- **Pooling layers:** reduce image size while retaining important features.\n",
    "- **Fully connected layers:** combine features to make predictions.\n",
    "\n",
    "CNNs learn by adjusting filters (kernels) during training using large labeled datasets.\n",
    "\n",
    "**Analogy:** Think of CNN as a set of digital microscopes that learn to detect patterns (e.g., nuclei, membranes) automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # example: background vs cell\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Modify the CNN above to have one more convolutional layer.\n",
    "- Change the activation function in the dense layer to 'sigmoid' and observe how it affects the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Deep Learning for Segmentation\n",
    "Traditional methods (thresholding, watershed) struggle with:\n",
    "- Noise\n",
    "- Irregular shapes\n",
    "- Overlapping cells\n",
    "\n",
    "**Deep learning segmentation learns directly from annotated examples:**\n",
    "- Learns what “cell” or “background” looks like.\n",
    "- Adapts to variations in shape, size, and texture.\n",
    "- **Common models:** U-Net, Cellpose, StarDist\n",
    "\n",
    "### Hands-On\n",
    "Visual comparison of classical vs deep learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = skimage.io.imread('example_image.tif')\n",
    "thresh = threshold_otsu(image)\n",
    "binary = image > thresh\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Threshold Segmentation\")\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then show how deep learning (e.g. using Cellpose) improves it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "model = models.Cellpose(model_type='cyto')\n",
    "masks, flows, styles, diams = model.eval(image, channels=[0,0])\n",
    "\n",
    "plt.imshow(masks, cmap='jet')\n",
    "plt.title(\"Cellpose Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Apply both thresholding and Cellpose to your own image.\n",
    "- Compare the segmentation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Popular Libraries: `TensorFlow`, `PyTorch`, `Keras`\n",
    "\n",
    "| Library        | Use Case          | Notes                                    |\n",
    "| -------------- | ----------------- | ---------------------------------------- |\n",
    "| **TensorFlow** | Industrial scale  | Google-developed, popular for production |\n",
    "| **PyTorch**    | Research          | Easy debugging, very Pythonic            |\n",
    "| **Keras**      | Beginner-friendly | Now part of TensorFlow                   |\n",
    "\n",
    "\n",
    "For beginners, Keras (via TensorFlow) is ideal due to its high-level API and clear syntax.\n",
    "\n",
    "### Hands-On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow + Keras Example\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(100,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# PyTorch Example\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Modify the above models to change number of neurons or activation.\n",
    "- Try loading an image dataset and pass one image through the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Input/Output for Imaging\n",
    "- **Input:** Images as NumPy arrays, shape often (height, width, channels)\n",
    "- **For grayscale:** channels = 1\n",
    "- **For RGB:** channels = 3\n",
    "\n",
    "**Output depends on task:**\n",
    "- **Classification:** One label per image\n",
    "- **Segmentation:** One label per pixel (output mask of same size)\n",
    "\n",
    "**Segmentation Workflow:**\n",
    "- **Preprocess:** resize, normalize\n",
    "- **Model:** CNN or U-Net\n",
    "- **Output:** binary or multiclass mask\n",
    "\n",
    "### Hands-On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "img = skimage.io.imread('cell_image.tif')\n",
    "img_resized = resize(img, (128,128), preserve_range=True).astype(np.float32)\n",
    "img_input = img_resized[np.newaxis, ..., np.newaxis]  # Shape: (1, 128, 128, 1)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Dummy prediction\n",
    "pred_mask = model.predict(img_input)\n",
    "plt.imshow(pred_mask[0,...,0], cmap='gray')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Take your own image and reshape it for input to a CNN.\n",
    "- Visualize the predicted output mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mini Project: Training a Simple U-Net on Synthetic Data\n",
    "**Goal:** Train a U-Net on synthetic blobs to learn segmentation.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "**Load data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a small U-Net (simplified):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def simple_unet(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model = simple_unet((128, 128, 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and evaluate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(images[..., np.newaxis], masks[..., np.newaxis], epochs=5, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict and visualize:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(images[:5, ..., np.newaxis])\n",
    "plt.imshow(preds[0,...,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module Summary\n",
    "| Topic                          | Concept                                | Hands-On                             | Outcome                                  |\n",
    "| ------------------------------ | -------------------------------------- | ------------------------------------ | ---------------------------------------- |\n",
    "| What is a CNN?                 | Understand convolutional layers        | Build a simple CNN                   | Learned how image features are extracted |\n",
    "| Deep Learning for Segmentation | Importance over classical methods      | Cellpose vs thresholding             | Saw quality improvements with DL         |\n",
    "| Libraries                      | Overview of TensorFlow, PyTorch, Keras | Defined models in both               | Understood basic syntax differences      |\n",
    "| Input/Output                   | Shape, format of image data            | Preprocess image and predict         | Able to run predictions on custom images |\n",
    "| Mini Project                   | Train U-Net on synthetic shapes        | Data generation, training, inference | Full pipeline for segmentation           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
